{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the Publishing Material Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are living in a world full of technology. Probably when we think about the 10 years challenge, we look back and think, how things have changed, how fast we have actually progressed and the sole reason is the level of research quality that is being done with the available resources. And because of so much research, there’s a huge competition between the new publishers and they look for really good marketing companies. And living in a digital world, people prefer to read articles online or watch videos rather than reading a book. As a member of a marketing agency, you’re given a dataset having the title, subjects and other features based on which you have to predict what will be the material of that to-be-published research so that you can tie-up with an ideal publisher and help them grow. The following are the material types:\n",
    "\n",
    "Book\n",
    "\n",
    "\n",
    "Sounddisc\n",
    "\n",
    "Videocass\n",
    "\n",
    "Soundcass\n",
    "\n",
    "Music\n",
    "\n",
    "Mixed\n",
    "\n",
    "Cr\n",
    "\n",
    "You have to predict the column “MaterialType” and please submit in the format given in the “sample_submissions.csv” file. Also, note evaluation criteria will be the weighted f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the files Train and Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Hacker earth/bf32d79c4a3711e9/Test/train_file.csv\")\n",
    "df2 = pd.read_csv(\"D:/Hacker earth/bf32d79c4a3711e9/Test/test_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>UsageClass</th>\n",
       "      <th>CheckoutType</th>\n",
       "      <th>CheckoutYear</th>\n",
       "      <th>CheckoutMonth</th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>PublicationYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31654</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Footprints at the window</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England Fiction, Space and time Fiction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31655</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Seven brides for seven brothers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Video recordings for the hearing impaired, Mus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31656</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>History [sound recording] / Loudon Wainwright ...</td>\n",
       "      <td>Wainwright, Loudon, III, 1946-</td>\n",
       "      <td>Popular music 1991 2000</td>\n",
       "      <td>Charisma,</td>\n",
       "      <td>p1992.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31657</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Doing big business on the internet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Internet, Internet advertising, Information ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31658</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Lets learn how to dance shag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shag Dance, Ballroom dancing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID UsageClass CheckoutType  CheckoutYear  CheckoutMonth  Checkouts  \\\n",
       "0  31654   Physical      Horizon          2005              4          1   \n",
       "1  31655   Physical      Horizon          2005              4          2   \n",
       "2  31656   Physical      Horizon          2005              4          2   \n",
       "3  31657   Physical      Horizon          2005              4          2   \n",
       "4  31658   Physical      Horizon          2005              4          2   \n",
       "\n",
       "                                               Title  \\\n",
       "0                           Footprints at the window   \n",
       "1                    Seven brides for seven brothers   \n",
       "2  History [sound recording] / Loudon Wainwright ...   \n",
       "3                 Doing big business on the internet   \n",
       "4                       Lets learn how to dance shag   \n",
       "\n",
       "                          Creator  \\\n",
       "0                             NaN   \n",
       "1                             NaN   \n",
       "2  Wainwright, Loudon, III, 1946-   \n",
       "3                             NaN   \n",
       "4                             NaN   \n",
       "\n",
       "                                            Subjects  Publisher  \\\n",
       "0            England Fiction, Space and time Fiction        NaN   \n",
       "1  Video recordings for the hearing impaired, Mus...        NaN   \n",
       "2                            Popular music 1991 2000  Charisma,   \n",
       "3  Internet, Internet advertising, Information ne...        NaN   \n",
       "4                       Shag Dance, Ballroom dancing        NaN   \n",
       "\n",
       "  PublicationYear  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2          p1992.  \n",
       "3             NaN  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31653, 12)\n",
      "(21102, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'UsageClass', 'CheckoutType', 'CheckoutYear', 'CheckoutMonth',\n",
      "       'Checkouts', 'Title', 'Creator', 'Subjects', 'Publisher',\n",
      "       'PublicationYear', 'MaterialType'],\n",
      "      dtype='object')\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Index(['ID', 'UsageClass', 'CheckoutType', 'CheckoutYear', 'CheckoutMonth',\n",
      "       'Checkouts', 'Title', 'Creator', 'Subjects', 'Publisher',\n",
      "       'PublicationYear'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(\"+\"*100)\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mearging both the files as so whatever preprocessing will be done , would be same on bothe files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixdf = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52755, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CheckoutMonth</th>\n",
       "      <th>CheckoutType</th>\n",
       "      <th>CheckoutYear</th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Creator</th>\n",
       "      <th>ID</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Title</th>\n",
       "      <th>UsageClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21097</th>\n",
       "      <td>4</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Costume History</td>\n",
       "      <td>History of womens costume</td>\n",
       "      <td>Physical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21098</th>\n",
       "      <td>4</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>Garland, Michael, 1952-</td>\n",
       "      <td>52752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003.</td>\n",
       "      <td>Dutton Children's Books,</td>\n",
       "      <td>Books and reading Juvenile fiction, Teachers J...</td>\n",
       "      <td>Miss Smith's incredible storybook / Michael Ga...</td>\n",
       "      <td>Physical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21099</th>\n",
       "      <td>4</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>Chesney, Marion</td>\n",
       "      <td>52753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.</td>\n",
       "      <td>St. Martin's Press,</td>\n",
       "      <td>Man woman relationships England Fiction, Famil...</td>\n",
       "      <td>Sir Philip's folly / Marion Chesney.</td>\n",
       "      <td>Physical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21100</th>\n",
       "      <td>4</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Video recordings for the hearing impaired, Fea...</td>\n",
       "      <td>Miss congeniality</td>\n",
       "      <td>Physical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21101</th>\n",
       "      <td>4</td>\n",
       "      <td>Horizon</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>Monroe, Bill, 1911-1996</td>\n",
       "      <td>52755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>p1989.</td>\n",
       "      <td>Hollywood,</td>\n",
       "      <td>Country music, Bluegrass music</td>\n",
       "      <td>At his best [sound recording] / Bill Monroe.</td>\n",
       "      <td>Physical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CheckoutMonth CheckoutType  CheckoutYear  Checkouts  \\\n",
       "21097              4      Horizon          2005          1   \n",
       "21098              4      Horizon          2005         10   \n",
       "21099              4      Horizon          2005          1   \n",
       "21100              4      Horizon          2005          6   \n",
       "21101              4      Horizon          2005          2   \n",
       "\n",
       "                       Creator     ID MaterialType PublicationYear  \\\n",
       "21097                      NaN  52751          NaN             NaN   \n",
       "21098  Garland, Michael, 1952-  52752          NaN           2003.   \n",
       "21099          Chesney, Marion  52753          NaN           1993.   \n",
       "21100                      NaN  52754          NaN             NaN   \n",
       "21101  Monroe, Bill, 1911-1996  52755          NaN          p1989.   \n",
       "\n",
       "                      Publisher  \\\n",
       "21097                       NaN   \n",
       "21098  Dutton Children's Books,   \n",
       "21099       St. Martin's Press,   \n",
       "21100                       NaN   \n",
       "21101                Hollywood,   \n",
       "\n",
       "                                                Subjects  \\\n",
       "21097                                    Costume History   \n",
       "21098  Books and reading Juvenile fiction, Teachers J...   \n",
       "21099  Man woman relationships England Fiction, Famil...   \n",
       "21100  Video recordings for the hearing impaired, Fea...   \n",
       "21101                     Country music, Bluegrass music   \n",
       "\n",
       "                                                   Title UsageClass  \n",
       "21097                          History of womens costume   Physical  \n",
       "21098  Miss Smith's incredible storybook / Michael Ga...   Physical  \n",
       "21099               Sir Philip's folly / Marion Chesney.   Physical  \n",
       "21100                                  Miss congeniality   Physical  \n",
       "21101       At his best [sound recording] / Bill Monroe.   Physical  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mixdf.shape)\n",
    "mixdf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see some columns have same values in complete data set , so it won't help us in finding pattern, So lets remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing useless feature which are same for all\n",
    "\n",
    "mixdf.drop(['ID', 'UsageClass', 'CheckoutType','CheckoutYear','CheckoutMonth'] , axis=1, inplace=True)\n",
    "\n",
    "#its done already once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52755, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixdf.head()\n",
    "mixdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Missing and Treating the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Checkouts              0\n",
       "Creator            38241\n",
       "MaterialType       21102\n",
       "PublicationYear    36173\n",
       "Publisher          36143\n",
       "Subjects            2976\n",
       "Title                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Creator</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tsunamis, Tsunamis Juvenile literature</td>\n",
       "      <td>Tidal wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Peck, Richard, 1934-</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>1998.</td>\n",
       "      <td>Viking,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London holiday / Richard Peck.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gnojewski, Carol</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>c2002.</td>\n",
       "      <td>Enslow Publishers,</td>\n",
       "      <td>Cinco de Mayo Mexican holiday History Juvenile...</td>\n",
       "      <td>Cinco de Mayo : celebrating Hispanic pride / C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>War stories, Historical fiction, Domestic fict...</td>\n",
       "      <td>Annapolis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thought and thinking</td>\n",
       "      <td>As a man thinketh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Cazet, Denys</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>c1998.</td>\n",
       "      <td>DK Pub.,</td>\n",
       "      <td>Cows Juvenile fiction, Parties Fiction, Farm l...</td>\n",
       "      <td>Minnie and Moo go dancing / [written and illus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mystery fiction, Qwilleran Jim Fictitious char...</td>\n",
       "      <td>cat who robbed a bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wall Street journal, Investments United States...</td>\n",
       "      <td>Irwin guide to using the Wall Street journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novelists American New York State New York Fic...</td>\n",
       "      <td>Oracle night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUNDDISC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rock music 1991 2000</td>\n",
       "      <td>12 haunted episodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Campbell, J. B.</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>1994.</td>\n",
       "      <td>Routledge,</td>\n",
       "      <td>Rome Italy Army</td>\n",
       "      <td>The Roman army, 31 BC-AD 337 : a sourcebook / ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>Ink Spots (Musical group)</td>\n",
       "      <td>SOUNDDISC</td>\n",
       "      <td>p1999.</td>\n",
       "      <td>MCA,</td>\n",
       "      <td>Popular music 1931 1940, Popular music 1941 1950</td>\n",
       "      <td>The Ink Spots [sound recording].</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Young, Donald J., 1930-</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>c1998.</td>\n",
       "      <td>Burd Street Press,</td>\n",
       "      <td>World War 1939 1945 Campaigns Pacific Area</td>\n",
       "      <td>First 24 hours of war in the Pacific / by Dona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Birds Habitat Juvenile literature, Birds Habitat</td>\n",
       "      <td>Where do birds live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VIDEOCASS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Video recordings for the hearing impaired, Sci...</td>\n",
       "      <td>Doctor Who The pirate planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia Civilization</td>\n",
       "      <td>Australia a cultural history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Horror tales American, Childrens stories American</td>\n",
       "      <td>Be afraid tales of horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Revolutionaries Nicaragua Biography, Nicaragua...</td>\n",
       "      <td>country under my skin a memoir of love and war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Nguyẽn, Hữu Nghĩa</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>1999.</td>\n",
       "      <td>Làng Văn,</td>\n",
       "      <td>Vietnam Politics and government 1975</td>\n",
       "      <td>Giai đoạn mới trên chiến trường cũ / Nguyễn Hữ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>Sierra, Judy</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>2004.</td>\n",
       "      <td>Knopf,</td>\n",
       "      <td>Zoo animals Juvenile fiction, Books and readin...</td>\n",
       "      <td>Wild about books / by Judy Sierra ; illustrate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Checkouts                    Creator MaterialType PublicationYear  \\\n",
       "0           1                        NaN         BOOK             NaN   \n",
       "1           1       Peck, Richard, 1934-         BOOK           1998.   \n",
       "2           3           Gnojewski, Carol         BOOK          c2002.   \n",
       "3           1                        NaN         BOOK             NaN   \n",
       "4           1                        NaN         BOOK             NaN   \n",
       "5           4               Cazet, Denys         BOOK          c1998.   \n",
       "6           1                        NaN         BOOK             NaN   \n",
       "7           1                        NaN         BOOK             NaN   \n",
       "8           4                        NaN         BOOK             NaN   \n",
       "9           1                        NaN    SOUNDDISC             NaN   \n",
       "10          1            Campbell, J. B.         BOOK           1994.   \n",
       "11          3  Ink Spots (Musical group)    SOUNDDISC          p1999.   \n",
       "12          1    Young, Donald J., 1930-         BOOK          c1998.   \n",
       "13          1                        NaN         BOOK             NaN   \n",
       "14          2                        NaN    VIDEOCASS             NaN   \n",
       "15          2                        NaN         BOOK             NaN   \n",
       "16          2                        NaN         BOOK             NaN   \n",
       "17          1                        NaN         BOOK             NaN   \n",
       "18          1          Nguyẽn, Hữu Nghĩa         BOOK           1999.   \n",
       "19         16               Sierra, Judy         BOOK           2004.   \n",
       "\n",
       "             Publisher                                           Subjects  \\\n",
       "0                  NaN             Tsunamis, Tsunamis Juvenile literature   \n",
       "1              Viking,                                                NaN   \n",
       "2   Enslow Publishers,  Cinco de Mayo Mexican holiday History Juvenile...   \n",
       "3                  NaN  War stories, Historical fiction, Domestic fict...   \n",
       "4                  NaN                               Thought and thinking   \n",
       "5             DK Pub.,  Cows Juvenile fiction, Parties Fiction, Farm l...   \n",
       "6                  NaN  Mystery fiction, Qwilleran Jim Fictitious char...   \n",
       "7                  NaN  Wall Street journal, Investments United States...   \n",
       "8                  NaN  Novelists American New York State New York Fic...   \n",
       "9                  NaN                               Rock music 1991 2000   \n",
       "10          Routledge,                                    Rome Italy Army   \n",
       "11                MCA,   Popular music 1931 1940, Popular music 1941 1950   \n",
       "12  Burd Street Press,         World War 1939 1945 Campaigns Pacific Area   \n",
       "13                 NaN   Birds Habitat Juvenile literature, Birds Habitat   \n",
       "14                 NaN  Video recordings for the hearing impaired, Sci...   \n",
       "15                 NaN                             Australia Civilization   \n",
       "16                 NaN  Horror tales American, Childrens stories American   \n",
       "17                 NaN  Revolutionaries Nicaragua Biography, Nicaragua...   \n",
       "18           Làng Văn,               Vietnam Politics and government 1975   \n",
       "19              Knopf,  Zoo animals Juvenile fiction, Books and readin...   \n",
       "\n",
       "                                                Title  \n",
       "0                                          Tidal wave  \n",
       "1                      London holiday / Richard Peck.  \n",
       "2   Cinco de Mayo : celebrating Hispanic pride / C...  \n",
       "3                                           Annapolis  \n",
       "4                                   As a man thinketh  \n",
       "5   Minnie and Moo go dancing / [written and illus...  \n",
       "6                               cat who robbed a bank  \n",
       "7        Irwin guide to using the Wall Street journal  \n",
       "8                                        Oracle night  \n",
       "9                                 12 haunted episodes  \n",
       "10  The Roman army, 31 BC-AD 337 : a sourcebook / ...  \n",
       "11                   The Ink Spots [sound recording].  \n",
       "12  First 24 hours of war in the Pacific / by Dona...  \n",
       "13                                Where do birds live  \n",
       "14                       Doctor Who The pirate planet  \n",
       "15                       Australia a cultural history  \n",
       "16                          Be afraid tales of horror  \n",
       "17     country under my skin a memoir of love and war  \n",
       "18  Giai đoạn mới trên chiến trường cũ / Nguyễn Hữ...  \n",
       "19  Wild about books / by Judy Sierra ; illustrate...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixdf.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the text data we can replace missing data as a empty string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixdf.Creator.fillna(' ', inplace=True)\n",
    "mixdf.Publisher.fillna(' ', inplace=True)\n",
    "mixdf.Subjects.fillna(' ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Creator</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Tsunamis, Tsunamis Juvenile literature</td>\n",
       "      <td>Tidal wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Peck, Richard, 1934-</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>1998.</td>\n",
       "      <td>Viking,</td>\n",
       "      <td></td>\n",
       "      <td>London holiday / Richard Peck.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gnojewski, Carol</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>c2002.</td>\n",
       "      <td>Enslow Publishers,</td>\n",
       "      <td>Cinco de Mayo Mexican holiday History Juvenile...</td>\n",
       "      <td>Cinco de Mayo : celebrating Hispanic pride / C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>War stories, Historical fiction, Domestic fict...</td>\n",
       "      <td>Annapolis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>BOOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Thought and thinking</td>\n",
       "      <td>As a man thinketh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Checkouts               Creator MaterialType PublicationYear  \\\n",
       "0          1                               BOOK             NaN   \n",
       "1          1  Peck, Richard, 1934-         BOOK           1998.   \n",
       "2          3      Gnojewski, Carol         BOOK          c2002.   \n",
       "3          1                               BOOK             NaN   \n",
       "4          1                               BOOK             NaN   \n",
       "\n",
       "            Publisher                                           Subjects  \\\n",
       "0                                 Tsunamis, Tsunamis Juvenile literature   \n",
       "1             Viking,                                                      \n",
       "2  Enslow Publishers,  Cinco de Mayo Mexican holiday History Juvenile...   \n",
       "3                      War stories, Historical fiction, Domestic fict...   \n",
       "4                                                   Thought and thinking   \n",
       "\n",
       "                                               Title  \n",
       "0                                         Tidal wave  \n",
       "1                     London holiday / Richard Peck.  \n",
       "2  Cinco de Mayo : celebrating Hispanic pride / C...  \n",
       "3                                          Annapolis  \n",
       "4                                  As a man thinketh  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a new dataframe which include all text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tsunamis, Tsunamis Juvenile literature Tsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peck, Richard, 1934- Viking,      London holid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gnojewski, Carol Enslow Publishers, Cinco de M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>War stories, Historical fiction, Domestic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thought and thinking Thought and thinking ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0      Tsunamis, Tsunamis Juvenile literature Tsu...\n",
       "1  Peck, Richard, 1934- Viking,      London holid...\n",
       "2  Gnojewski, Carol Enslow Publishers, Cinco de M...\n",
       "3      War stories, Historical fiction, Domestic ...\n",
       "4      Thought and thinking Thought and thinking ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Selecting words start\n",
    "new =  pd.DataFrame(columns=['Text'])\n",
    "new['Text'] = mixdf['Creator'] +\" \" + mixdf['Publisher'] + \" \" + (mixdf['Subjects']+ ' ')*2 + \" \" + mixdf['Title'] \n",
    "\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering before data preprocessing:\n",
    "    Let's create some new feature which might be helpful in prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>unique_percentage</th>\n",
       "      <th>w_notin_stop</th>\n",
       "      <th>Feature_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tsunamis, Tsunamis Juvenile literature Tsu...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peck, Richard, 1934- Viking,      London holid...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gnojewski, Carol Enslow Publishers, Cinco de M...</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>War stories, Historical fiction, Domestic ...</td>\n",
       "      <td>67</td>\n",
       "      <td>18</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thought and thinking Thought and thinking ...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  word_count  \\\n",
       "0      Tsunamis, Tsunamis Juvenile literature Tsu...          10   \n",
       "1  Peck, Richard, 1934- Viking,      London holid...           9   \n",
       "2  Gnojewski, Carol Enslow Publishers, Cinco de M...         100   \n",
       "3      War stories, Historical fiction, Domestic ...          67   \n",
       "4      Thought and thinking Thought and thinking ...          10   \n",
       "\n",
       "   unique_words  unique_percentage  w_notin_stop  Feature_4  \n",
       "0             6           0.600000            10          0  \n",
       "1             9           1.000000             9          0  \n",
       "2            31           0.310000            94          6  \n",
       "3            18           0.268657            67          0  \n",
       "4             7           0.700000             7          4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "new['word_count'] = new['Text'].apply(lambda x : len(x.split()))\n",
    "\n",
    "new['unique_words'] = new['Text'].apply(lambda x : len(set(x.split())))\n",
    "\n",
    "\n",
    "new['unique_percentage'] =  new['unique_words']/new['word_count']\n",
    "\n",
    "new['w_notin_stop'] =  new['Text'].apply(lambda x : len([w for w in str(x).split() if w not in stop_words]))\n",
    "\n",
    "new['Feature_4'] = new['Text'].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]) )\n",
    "\n",
    "\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning of text data.\n",
    "Here tqdm used to show progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52755/52755 [01:54<00:00, 460.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:01:54.658929\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "preprocessed_data_list=[]\n",
    "finaltext = ' '\n",
    "\n",
    "\n",
    "for row in tqdm(range(len(mixdf))):\n",
    "    \n",
    "    finaltext = str(mixdf.iloc[row,1]) +\" \" + str(mixdf.iloc[row,4]) + \" \" + str((mixdf.iloc[row,5] + ' '))*2 + \" \" + str(mixdf.iloc[row,6]) \n",
    "\n",
    "    finaltext = re.sub(r'[^A-Za-z]+', ' ', finaltext)\n",
    "\n",
    "    words = word_tokenize(str(finaltext.lower()))\n",
    "    \n",
    "    finaltext =    ' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and len(j)!=1) \n",
    "  \n",
    "    preprocessed_data_list.append(finaltext)\n",
    "\n",
    "    \n",
    "print(\"Time taken to run this cell :\", datetime.datetime.now() - start)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52755, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tsunami tsunami juvenil literatur tsunami tsun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peck richard vike london holiday richard peck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gnojewski carol enslow publish cinco de mayo m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>war stori histor fiction domest fiction sea st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thought think thought think man thinketh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  tsunami tsunami juvenil literatur tsunami tsun...\n",
       "1      peck richard vike london holiday richard peck\n",
       "2  gnojewski carol enslow publish cinco de mayo m...\n",
       "3  war stori histor fiction domest fiction sea st...\n",
       "4           thought think thought think man thinketh"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data = pd.DataFrame(preprocessed_data_list, columns=['Text'])\n",
    "\n",
    "print(preprocessed_data.shape)\n",
    "\n",
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create Dummy variables for multiclass classification using Beg of Words techninque. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Multiclass Classification Dataframe:   (31653, 8)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(binary=True)\n",
    "multilable_y = vectorizer.fit_transform(df.MaterialType)\n",
    "\n",
    "print(\"Shape of Multiclass Classification Dataframe:  \", multilable_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>unique_percentage</th>\n",
       "      <th>w_notin_stop</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Checkouts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tsunamis, Tsunamis Juvenile literature Tsu...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peck, Richard, 1934- Viking,      London holid...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gnojewski, Carol Enslow Publishers, Cinco de M...</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>War stories, Historical fiction, Domestic ...</td>\n",
       "      <td>67</td>\n",
       "      <td>18</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thought and thinking Thought and thinking ...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  word_count  \\\n",
       "0      Tsunamis, Tsunamis Juvenile literature Tsu...          10   \n",
       "1  Peck, Richard, 1934- Viking,      London holid...           9   \n",
       "2  Gnojewski, Carol Enslow Publishers, Cinco de M...         100   \n",
       "3      War stories, Historical fiction, Domestic ...          67   \n",
       "4      Thought and thinking Thought and thinking ...          10   \n",
       "\n",
       "   unique_words  unique_percentage  w_notin_stop  Feature_4  Checkouts  \n",
       "0             6           0.600000            10          0          1  \n",
       "1             9           1.000000             9          0          1  \n",
       "2            31           0.310000            94          6          3  \n",
       "3            18           0.268657            67          0          1  \n",
       "4             7           0.700000             7          4          1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding the Checkout variable in  new dataframe\n",
    "\n",
    "new['Checkouts'] = mixdf['Checkouts'].values\n",
    "\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Material Type only appear a few times, with very few Material type appearing several times (and Book appearing many times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "sns.countplot(mixdf['MaterialType'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I'm now going to try to improve this feature, by using something called TF-IDF (term-frequency-inverse-document-frequency). This means that we weigh the terms by how uncommon they are, meaning that we care more about rare words existing in Text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda x : x.split(), ngram_range=(1,3))\n",
    "\n",
    "tfidf_mat = tfidf.fit_transform(new['Text'])\n",
    "\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here aftre TF-IDF we have shape of Dataframe :   (52755, 1069839)\n"
     ]
    }
   ],
   "source": [
    "print(\"Here aftre TF-IDF we have shape of Dataframe :  \",tfidf_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here we will divide both Train and Test File again.\n",
    "In which train_df include Target variable and test_df don''t have Traget variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Test Dataframe :   (31653, 1069839)\n",
      "Shape of Test Dataframe :   (21102, 1069839)\n"
     ]
    }
   ],
   "source": [
    "train_df = tfidf_mat[:31653,]\n",
    "\n",
    "test_df= tfidf_mat[31653:,]  \n",
    "\n",
    "print(\"Shape of Test Dataframe :  \",train_df.shape)\n",
    "print(\"Shape of Test Dataframe :  \",test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the dataframe into train for model creation and test dataframe to test the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25322, 1069839) (6331, 1069839) (25322, 8) (6331, 8)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(train_df, multilable_y, random_state = 0, test_size = 0.2)\n",
    "\n",
    "print(X_train.shape ,X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameter tunning for SGD classifier.\n",
    "\n",
    "read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "------------------------------\n",
    "default parameters\n",
    "SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "some of methods\n",
    "fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "\n",
    "Here we are using L1 regulrization as we have so many variables to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the best value of alpha :   {'estimator__alpha': 1.584893192461114e-05}\n"
     ]
    }
   ],
   "source": [
    "param_grid  = {\"estimator__alpha\": [ 10**-5.2, 10**-5.1,10**-4.9,10**-4.8]}\n",
    "\n",
    "clf1 = OneVsRestClassifier(SGDClassifier(loss='hinge',penalty='l1'))\n",
    "\n",
    "clf1 = GridSearchCV(clf1,param_grid, scoring = 'f1_micro', n_jobs=-1)\n",
    "\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "clf1_train_pred = clf1.predict(X_train)\n",
    "\n",
    "clf1_test_pred = clf1.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Here is the best value of alpha :  \",clf1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data micro f1 scoore : 0.9061203319502075\n",
      "Testing Data micro f1 scoore : 0.888959846731061\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data micro f1 scoore :\",metrics.f1_score(y_train, clf1.predict(X_train), average = 'micro'))\n",
    "\n",
    "print(\"Testing Data micro f1 scoore :\",metrics.f1_score(y_test, clf1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work on remaining features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now we have created model for only text data , So we have to include other variable to , So i am training a new model for remaining variable and then we will mearge both the model using STACKING techinuqe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text                 0\n",
       "word_count           0\n",
       "unique_words         0\n",
       "unique_percentage    0\n",
       "w_notin_stop         0\n",
       "Feature_4            0\n",
       "Checkouts            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New dataframes (Train and Test) for remaining variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>unique_percentage</th>\n",
       "      <th>w_notin_stop</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Checkouts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>18</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  unique_words  unique_percentage  w_notin_stop  Feature_4  \\\n",
       "0          10             6           0.600000            10          0   \n",
       "1           9             9           1.000000             9          0   \n",
       "2         100            31           0.310000            94          6   \n",
       "3          67            18           0.268657            67          0   \n",
       "4          10             7           0.700000             7          4   \n",
       "\n",
       "   Checkouts  \n",
       "0          1  \n",
       "1          1  \n",
       "2          3  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nfeatures =  new[:31653][['word_count','unique_words','unique_percentage','w_notin_stop','Feature_4','Checkouts']]\n",
    "\n",
    "train_df_nfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train datframe of remaining variables :   (31653, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train datframe of remaining variables :  \",train_df_nfeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>unique_percentage</th>\n",
       "      <th>w_notin_stop</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Checkouts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  unique_words  unique_percentage  w_notin_stop  Feature_4  \\\n",
       "0          16            10           0.625000            12          4   \n",
       "1          21            12           0.571429            16          5   \n",
       "2          20            16           0.800000            20          0   \n",
       "3          26            16           0.615385            24          3   \n",
       "4          14            10           0.714286            12          2   \n",
       "\n",
       "   Checkouts  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_nfeatures = new[31653:][['word_count','unique_words','unique_percentage','w_notin_stop','Feature_4','Checkouts']]\n",
    "\n",
    "test_df_nfeatures.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train datframe of remaining variables :   (21102, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train datframe of remaining variables :  \",test_df_nfeatures.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into train and test dataframe to Train model and to validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25322, 6) (6331, 6) (25322, 8) (6331, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_df_train,X_df_test, y_df_train,y_df_test = train_test_split(train_df_nfeatures, multilable_y, random_state=0, test_size = 0.2)\n",
    "\n",
    "print(X_df_train.shape,X_df_test.shape, y_df_train.shape,y_df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again we are using SGDclassifier where loss function will be Hinge loss from SVM.\n",
    " and we are using L2 Regularization to prevent overfitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid  = {\"estimator__alpha\": [0.001,0.001,0.01,0.1]}\n",
    "\n",
    "clf2 = OneVsRestClassifier(SGDClassifier(loss='hinge',penalty='l2'))\n",
    "\n",
    "clf2 = GridSearchCV(clf2,param_grid, scoring = 'f1_micro', n_jobs=-1)\n",
    "\n",
    "clf2.fit(X_df_train, y_df_train)\n",
    "\n",
    "\n",
    "clf2_train_pred = clf2.predict(X_df_train)\n",
    "\n",
    "clf2_test_pred = clf2.predict(X_df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the best value of alpha :   {'estimator__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is the best value of alpha :  \", clf2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data micro f1 scoore : 0.6644292414267889\n",
      "Testing Data micro f1 scoore : 0.6672407853944196\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data micro f1 scoore :\",metrics.f1_score(y_df_train, clf2.predict(X_df_train), average = 'micro'))\n",
    "\n",
    "print(\"Testing Data micro f1 scoore :\",metrics.f1_score(y_df_test, clf2.predict(X_df_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking of both model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can build multiple different learners and you use them to build an intermediate prediction, one prediction for each learned model. Then you add a new model which learns from the intermediate predictions the same target. This final model is said to be stacked on the top of the others, hence the name. Thus you might improve your overall performance, and often you end up with a model which is better than any individual intermediate model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25322, 8) (25322, 8) (6331, 8) (6331, 8)\n"
     ]
    }
   ],
   "source": [
    "print(clf1_train_pred.shape, clf2_train_pred.shape, clf1_test_pred.shape, clf2_test_pred.shape)\n",
    "\n",
    "clf1_train_pred = pd.DataFrame(clf1_train_pred.toarray())\n",
    "clf1_test_pred = pd.DataFrame(clf1_test_pred.toarray())\n",
    "clf2_train_pred = pd.DataFrame(clf2_train_pred.toarray())\n",
    "clf2_test_pred = pd.DataFrame(clf2_test_pred.toarray())\n",
    "\n",
    "df_train = pd.concat([clf1_train_pred,clf2_train_pred], axis=1, sort=False)\n",
    "df_test = pd.concat([clf1_test_pred,clf2_test_pred], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Model with hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l1', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
       "          n_jobs=1),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'estimator__alpha': [3.1622776601683795e-05, 0.0001, 0.00012589254117941674, 6309.57344480193, 0.0002818382931264455, 0.00031622776601683794, 0.00039810717055349735, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid  = {\"estimator__alpha\": [ 10**-4.5,10**-4,10**-3.9,10**3.8, 10**-3.55,10**-3.5,10**-3.4, 10**-1]}\n",
    "\n",
    "stackclf = OneVsRestClassifier(SGDClassifier(loss='hinge',penalty='l1'))\n",
    "\n",
    "stackclf = GridSearchCV(stackclf,param_grid, scoring = 'f1_micro', n_jobs=-1)\n",
    "\n",
    "\n",
    "stackclf.fit(df_train, y_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the best value of alpha :   {'estimator__alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is the best value of alpha :  \" , stackclf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data micro f1 scoore : 0.9067018132438692\n",
      "Testing Data micro f1 scoore : 0.8889953681520524\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data micro f1 scoore :\",metrics.f1_score(y_df_train, stackclf.predict(df_train), average = 'micro'))\n",
    "\n",
    "print(\"Testing Data micro f1 scoore :\",metrics.f1_score(y_df_test, stackclf.predict(df_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data micro f1 scoore : 0.9067018132438692\n",
      "Testing Data micro f1 scoore : 0.8889953681520524\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data micro f1 scoore :\",metrics.f1_score(y_df_train, stackclf.predict(df_train), average = 'micro'))\n",
    "\n",
    "print(\"Testing Data micro f1 scoore :\",metrics.f1_score(y_df_test, stackclf.predict(df_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21102, 8)\n",
      "(21102, 8)\n"
     ]
    }
   ],
   "source": [
    "testpre = clf1.predict(test_df)\n",
    "\n",
    "testpre_check = clf2.predict(test_df_nfeatures)\n",
    "\n",
    "print(testpre.shape)\n",
    "print(testpre_check.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21102, 8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpre = pd.DataFrame(testpre.toarray())\n",
    "testpre_check = pd.DataFrame(testpre_check.toarray())\n",
    "\n",
    "\n",
    "testdata = pd.concat([testpre,testpre_check], axis=1, sort=False)\n",
    "\n",
    "test_prediction_final = stackclf.predict(testdata)\n",
    "\n",
    "test_prediction_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction_final.toarray()[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['book',\n",
       " 'cr',\n",
       " 'mixed',\n",
       " 'music',\n",
       " 'soundcass',\n",
       " 'sounddisc',\n",
       " 'videocass',\n",
       " 'videodisc']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaterialType</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31654</th>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31655</th>\n",
       "      <td>VIDEOCASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31656</th>\n",
       "      <td>SOUNDDISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31657</th>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31658</th>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31659</th>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31660</th>\n",
       "      <td>SOUNDDISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31661</th>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31662</th>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31663</th>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MaterialType\n",
       "ID                \n",
       "31654         BOOK\n",
       "31655    VIDEOCASS\n",
       "31656    SOUNDDISC\n",
       "31657         BOOK\n",
       "31658         BOOK\n",
       "31659         BOOK\n",
       "31660    SOUNDDISC\n",
       "31661         BOOK\n",
       "31662         BOOK\n",
       "31663         BOOK"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['BOOK','CR', 'MIXED', 'MUSIC', 'SOUNDCASS', 'SOUNDDISC','VIDEOCASS','VIDEODISC' ]\n",
    "\n",
    "lab = [labels[test_prediction_final.toarray().argmax(axis=1)[i]] for i in range(len(test_prediction_final.toarray()))]\n",
    "\n",
    "csvdf = pd.DataFrame(lab,columns=['MaterialType'], index= df2.ID)\n",
    "\n",
    "csvdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvdf.to_csv(\"D:/Hacker earth/bf32d79c4a3711e9/Test/final_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
